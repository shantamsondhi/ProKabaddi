{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium  import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "driver = webdriver.Chrome(\"/home/shantam/Downloads/chromedriver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.prokabaddi.com')\n",
    "time.sleep(1)\n",
    "standings=driver.find_element_by_link_text(\"Standings\")\n",
    "standings.click()\n",
    "#### TO WRITE DRIVER PAGE AS HTML\n",
    "#soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "# with open(\"StandingsPage1.html\", \"w\") as file:\n",
    "#     file.write(str(soup))\n",
    "time.sleep(2)\n",
    "tableCOntent=driver.find_element_by_class_name(\"sipk-standing-page \")\n",
    "table=tableCOntent.text\n",
    "table=table.split('\\n')[1:]\n",
    "while True:\n",
    "    try:\n",
    "        table.remove('Q') ## Website has added 'Q' mark for qualified teams\n",
    "    except:\n",
    "        break\n",
    "\n",
    "numberOfColumns=8\n",
    "numberOfTeams=12\n",
    "columns=table[:numberOfColumns]\n",
    "tablevalues=[]\n",
    "for i in range(numberOfColumns,len(table),numberOfColumns):\n",
    "    tablevalues.append(table[i:i+numberOfColumns])\n",
    "tablevalues=tablevalues[:numberOfTeams]\n",
    "LeagueTable=pd.DataFrame.from_records(tablevalues,columns=columns)\n",
    "LeagueTable.to_csv(\"./LT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flashscore.com.au/kabaddi/india/pro-kabaddi/results/')\n",
    "time.sleep(1)\n",
    "fixtureHistory=driver.find_element_by_id(\"live-table\")\n",
    "fixtureHistory=fixtureHistory.text.split('\\n')[3:]\n",
    "# #### TO WRITE DRIVER PAGE AS HTML\n",
    "# soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "# with open(\"ResultsPage.html\", \"w\") as file:\n",
    "#     file.write(str(soup))\n",
    "\n",
    "columns=['Date','HomeTeam','AwayTeam','Total_Points_HomeTeam','Total_Points_AwayTeam','FirstHalf_Points_HomeTeam','FirstHalf_Points_AwayTeam','SecondHalf_Points_HomeTeam','SecondHalf_Points_AwayTeam']\n",
    "tablevalues=[]\n",
    "for i in range(0,len(fixtureHistory)-1,len(columns)):\n",
    "    tablevalues.append(fixtureHistory[i:i+len(columns)])\n",
    "ResultsTable=pd.DataFrame.from_records(tablevalues,columns=columns)\n",
    "ResultsTable.to_csv('./Points_Table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flashscore.com.au/kabaddi/india/pro-kabaddi/fixtures/')\n",
    "time.sleep(1)\n",
    "fixtureUpcoming=driver.find_element_by_id(\"live-table\").text.split('\\n')[3:]\n",
    "fixtureUpcoming\n",
    "columns=['date','HomeTeam','AwayTeam','Drop1','Drop2']\n",
    "tablevalues=[]\n",
    "for i in range(0,len(fixtureUpcoming),len(columns)):\n",
    "    tablevalues.append(fixtureUpcoming[i:i+len(columns)])\n",
    "UpcomingTable=pd.DataFrame.from_records(tablevalues,columns=columns)\n",
    "UpcomingTable=UpcomingTable.drop(['Drop1','Drop2'],axis=1)\n",
    "UpcomingTable.to_csv('./UF.csv')\n",
    "\n",
    "# #### TO WRITE DRIVER PAGE AS HTML\n",
    "# soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "# with open(\"FixturesPage.html\", \"w\") as file:\n",
    "#     file.write(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flashscore.com.au/kabaddi/india/pro-kabaddi/results/')\n",
    "time.sleep(1)\n",
    "elem = driver.find_element_by_id('g_42_lK3wjznt').click()\n",
    "time.sleep(1)\n",
    "window_before = driver.window_handles[0]\n",
    "window_after = driver.window_handles[1]\n",
    "driver.switch_to_window(window_after)\n",
    "soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "with open(\"matchPage.html\", \"w\") as file:\n",
    "    file.write(str(soup))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
